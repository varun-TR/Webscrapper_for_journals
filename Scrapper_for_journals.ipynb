{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a3535dd",
   "metadata": {},
   "source": [
    "# The program is at bottom mentoned as \"Automating publish dates - final code\" this is the code that is used to scrap the given website\n",
    "\n",
    "\n",
    "## The output is saved in 3 different varients:\n",
    "## 1. As pandas dataframe\n",
    "## 2. As excel file\n",
    "## 3. As csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fb78a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /Users/trsaivarun/anaconda3/lib/python3.11/site-packages (2.29.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/trsaivarun/anaconda3/lib/python3.11/site-packages (4.12.2)\n",
      "Requirement already satisfied: pandas in /Users/trsaivarun/anaconda3/lib/python3.11/site-packages (1.5.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/trsaivarun/anaconda3/lib/python3.11/site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/trsaivarun/anaconda3/lib/python3.11/site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/trsaivarun/anaconda3/lib/python3.11/site-packages (from requests) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/trsaivarun/anaconda3/lib/python3.11/site-packages (from requests) (2024.2.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/trsaivarun/anaconda3/lib/python3.11/site-packages (from beautifulsoup4) (2.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/trsaivarun/anaconda3/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/trsaivarun/anaconda3/lib/python3.11/site-packages (from pandas) (2022.7)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /Users/trsaivarun/anaconda3/lib/python3.11/site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/trsaivarun/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install requests beautifulsoup4 pandas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f12f10",
   "metadata": {},
   "source": [
    "## Final code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6e17c951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing section for abstract. Error: Message: \n",
      "Stacktrace:\n",
      "0   chromedriver                        0x0000000102c11024 cxxbridge1$str$ptr + 1887276\n",
      "1   chromedriver                        0x0000000102c09700 cxxbridge1$str$ptr + 1856264\n",
      "2   chromedriver                        0x000000010281882c cxxbridge1$string$len + 88524\n",
      "3   chromedriver                        0x000000010285c834 cxxbridge1$string$len + 367060\n",
      "4   chromedriver                        0x0000000102852e38 cxxbridge1$string$len + 327640\n",
      "5   chromedriver                        0x000000010289448c cxxbridge1$string$len + 595500\n",
      "6   chromedriver                        0x0000000102851474 cxxbridge1$string$len + 321044\n",
      "7   chromedriver                        0x00000001028520e4 cxxbridge1$string$len + 324228\n",
      "8   chromedriver                        0x0000000102bd8a08 cxxbridge1$str$ptr + 1656336\n",
      "9   chromedriver                        0x0000000102bdd464 cxxbridge1$str$ptr + 1675372\n",
      "10  chromedriver                        0x0000000102bbe8ec cxxbridge1$str$ptr + 1549556\n",
      "11  chromedriver                        0x0000000102bddc14 cxxbridge1$str$ptr + 1677340\n",
      "12  chromedriver                        0x0000000102bb05fc cxxbridge1$str$ptr + 1491460\n",
      "13  chromedriver                        0x0000000102bfaa5c cxxbridge1$str$ptr + 1795684\n",
      "14  chromedriver                        0x0000000102bfabd8 cxxbridge1$str$ptr + 1796064\n",
      "15  chromedriver                        0x0000000102c09334 cxxbridge1$str$ptr + 1855292\n",
      "16  libsystem_pthread.dylib             0x00000001a4a5ffa8 _pthread_start + 148\n",
      "17  libsystem_pthread.dylib             0x00000001a4a5ada0 thread_start + 8\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Affiliations-ORCID IDs</th>\n",
       "      <th>Publish Date</th>\n",
       "      <th>DOI URL</th>\n",
       "      <th>Abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Caring Machine: Feeling AI for Customer Care</td>\n",
       "      <td>Ming-Hui Huang\\nRoland T. Rust</td>\n",
       "      <td>https://orcid.org/0000-0001-8954-3172, https:/...</td>\n",
       "      <td>First published March 22, 2024</td>\n",
       "      <td>https://journals.sagepub.com/doi/abs/10.1177/0...</td>\n",
       "      <td>Abstract\\nCustomer care is important for its r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Consequences of Marketing Asset Accountability...</td>\n",
       "      <td>Peter Guenther\\nMiriam Guenther\\nBryan A. Luka...</td>\n",
       "      <td>https://orcid.org/0000-0001-6033-8466</td>\n",
       "      <td>First published April 22, 2024</td>\n",
       "      <td>https://journals.sagepub.com/doi/abs/10.1177/0...</td>\n",
       "      <td>Abstract\\nMarketing scholars have extensively ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Developing Strengths or Remedying Weaknesses? ...</td>\n",
       "      <td>Qihui Chen\\nYajin Wang\\nYing Zhang</td>\n",
       "      <td>https://orcid.org/0009-0005-0623-6385, https:/...</td>\n",
       "      <td>First published May 6, 2024</td>\n",
       "      <td>https://journals.sagepub.com/doi/abs/10.1177/0...</td>\n",
       "      <td>Abstract\\nDoes parents’ status motivation affe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>More Likely to Pay but Less Engaged: The Effec...</td>\n",
       "      <td>Joy Lu\\nEric T. Bradlow\\nJ. Wesley Hutchinson</td>\n",
       "      <td>https://orcid.org/0000-0001-7132-7105</td>\n",
       "      <td>First published March 20, 2024</td>\n",
       "      <td>https://journals.sagepub.com/doi/abs/10.1177/0...</td>\n",
       "      <td>Abstract\\nFollowing trends in entertainment st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>So, Sue Me…If You Can! How Legal Changes Dimin...</td>\n",
       "      <td>Arvid O.I. Hoffmann\\nChee S. Cheong\\nHoàng-Lon...</td>\n",
       "      <td>https://orcid.org/0000-0003-4148-5078, https:/...</td>\n",
       "      <td>First published April 7, 2024</td>\n",
       "      <td>https://journals.sagepub.com/doi/abs/10.1177/0...</td>\n",
       "      <td>Abstract\\nResearch examining the antecedents o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0   The Caring Machine: Feeling AI for Customer Care   \n",
       "1  Consequences of Marketing Asset Accountability...   \n",
       "2  Developing Strengths or Remedying Weaknesses? ...   \n",
       "3  More Likely to Pay but Less Engaged: The Effec...   \n",
       "4  So, Sue Me…If You Can! How Legal Changes Dimin...   \n",
       "\n",
       "                                             Authors  \\\n",
       "0                     Ming-Hui Huang\\nRoland T. Rust   \n",
       "1  Peter Guenther\\nMiriam Guenther\\nBryan A. Luka...   \n",
       "2                 Qihui Chen\\nYajin Wang\\nYing Zhang   \n",
       "3      Joy Lu\\nEric T. Bradlow\\nJ. Wesley Hutchinson   \n",
       "4  Arvid O.I. Hoffmann\\nChee S. Cheong\\nHoàng-Lon...   \n",
       "\n",
       "                              Affiliations-ORCID IDs  \\\n",
       "0  https://orcid.org/0000-0001-8954-3172, https:/...   \n",
       "1              https://orcid.org/0000-0001-6033-8466   \n",
       "2  https://orcid.org/0009-0005-0623-6385, https:/...   \n",
       "3              https://orcid.org/0000-0001-7132-7105   \n",
       "4  https://orcid.org/0000-0003-4148-5078, https:/...   \n",
       "\n",
       "                     Publish Date  \\\n",
       "0  First published March 22, 2024   \n",
       "1  First published April 22, 2024   \n",
       "2     First published May 6, 2024   \n",
       "3  First published March 20, 2024   \n",
       "4   First published April 7, 2024   \n",
       "\n",
       "                                             DOI URL  \\\n",
       "0  https://journals.sagepub.com/doi/abs/10.1177/0...   \n",
       "1  https://journals.sagepub.com/doi/abs/10.1177/0...   \n",
       "2  https://journals.sagepub.com/doi/abs/10.1177/0...   \n",
       "3  https://journals.sagepub.com/doi/abs/10.1177/0...   \n",
       "4  https://journals.sagepub.com/doi/abs/10.1177/0...   \n",
       "\n",
       "                                            Abstract  \n",
       "0  Abstract\\nCustomer care is important for its r...  \n",
       "1  Abstract\\nMarketing scholars have extensively ...  \n",
       "2  Abstract\\nDoes parents’ status motivation affe...  \n",
       "3  Abstract\\nFollowing trends in entertainment st...  \n",
       "4  Abstract\\nResearch examining the antecedents o...  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# Initialize the WebDriver and load the page\n",
    "driver = webdriver.Chrome()\n",
    "url = 'https://journals.sagepub.com/toc/JMX/current'\n",
    "driver.get(url)\n",
    "\n",
    "# Allow the page to load completely\n",
    "WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, 'table-of-content')))\n",
    "\n",
    "# Find the div with the class 'table-of-content'\n",
    "content_div = driver.find_element(By.CLASS_NAME, 'table-of-content')\n",
    "\n",
    "# Find all section tags within this div\n",
    "sections = content_div.find_elements(By.TAG_NAME, 'section')\n",
    "\n",
    "# List to store extracted data\n",
    "data = []\n",
    "\n",
    "# Iterate over each section\n",
    "for section in sections:\n",
    "    try:\n",
    "        # Locate the \"Preview abstract\" button using its attributes\n",
    "        preview_button = WebDriverWait(section, 10).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, \".//button[@data-toggle='collapse' and contains(@class, 'btn-link')]\"))\n",
    "        )\n",
    "        preview_button.click()\n",
    "        \n",
    "        # Wait for the abstract content to become visible\n",
    "        WebDriverWait(section, 10).until(\n",
    "            EC.visibility_of_element_located((By.XPATH, \".//div[contains(@class, 'issue-item__abstract__content') and contains(@class, 'collapse') and contains(@class, 'show')]\"))\n",
    "        )\n",
    "        \n",
    "        # Extract the abstract content\n",
    "        abstract_element = section.find_element(By.XPATH, \".//div[contains(@class, 'issue-item__abstract__content') and contains(@class, 'collapse') and contains(@class, 'show')]\")\n",
    "        abstract_text = abstract_element.text\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing section for abstract. Error: {e}\")\n",
    "        abstract_text = \"Abstract not available\"\n",
    "\n",
    "    # Extract titles, authors, publish dates, DOI URLs, and affiliations\n",
    "    titles = section.find_elements(By.CLASS_NAME, 'issue-item__heading')\n",
    "    authors = section.find_elements(By.CLASS_NAME, 'issue-item__authors')\n",
    "    title_links = section.find_elements(By.CLASS_NAME, 'issue-item__title')\n",
    "    doi_urls = [link.find_element(By.TAG_NAME, 'a').get_attribute('href') for link in title_links]\n",
    "    \n",
    "    # Extract publish date using the div with the class 'issue-item__header'\n",
    "    try:\n",
    "        header = section.find_element(By.CLASS_NAME, 'issue-item__header')\n",
    "        publish_date = header.find_element(By.XPATH, \".//span[.//text()[contains(., 'First published')]]\").text\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing publish date. Error: {e}\")\n",
    "        publish_date = \"Publish Date not available\"\n",
    "\n",
    "    # Gather and store data\n",
    "    for j, title in enumerate(titles):\n",
    "        author_element = authors[j] if j < len(authors) else None\n",
    "        orcids = []\n",
    "        affiliations_text = ''\n",
    "\n",
    "        if author_element:\n",
    "            # Extract ORCID IDs and affiliations\n",
    "            orcid_elements = author_element.find_elements(By.CLASS_NAME, 'orcid-id')\n",
    "            orcids = [orcid.get_attribute('href') for orcid in orcid_elements]\n",
    "            \n",
    "            affiliations = author_element.find_elements(By.CLASS_NAME, 'author-affiliation')  # Adjust class name as needed\n",
    "            affiliations_text = ', '.join([affil.text for affil in affiliations])\n",
    "            \n",
    "            author_text = author_element.text\n",
    "        else:\n",
    "            author_text = 'Authors not available'\n",
    "\n",
    "        row = {\n",
    "            'Title': title.text,\n",
    "            'Authors': author_text,\n",
    "            'Affiliations-ORCID IDs': ', '.join(orcids),\n",
    "            'Publish Date': publish_date,\n",
    "            'DOI URL': doi_urls[j] if j < len(doi_urls) else 'DOI URL not available',\n",
    "            'Abstract': abstract_text\n",
    "        }\n",
    "        data.append(row)\n",
    "\n",
    "# Create a DataFrame from the data\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "#Neglect below error - this is because final article doesn't have proper information to scrap from website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b4af1ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('/Users/trsaivarun/Desktop/c_py:R/assignment-2/output-final.xlsx', sheet_name='sheet1', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "abc88611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving as csv - according to UTF-8 encodings\n",
    "df['Abstract'] = df['Abstract'].str.replace('\\n', ' ', regex=False)\n",
    "df['Authors'] = df['Authors'].str.replace('\\n', ', ', regex=False)\n",
    "df.to_csv('/Users/trsaivarun/Desktop/c_py:R/assignment-2/output-final.csv', index=False, sep='\\t', encoding='utf-8-sig')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5490f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
